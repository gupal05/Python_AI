{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 설치 : pip install konlpy\n",
    "from konlpy.tag import Okt # 토크나이징\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # 인코딩\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding # 임베딩\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 텍스트 데이터 (입력 문장)\n",
    "sentences = [\n",
    "    \"자연어 처리는 재미있는 분야입니다.\",\n",
    "    \"딥러닝은 많은 데이터를 필요로 합니다.\",\n",
    "    \"한국어 NLP는 정말 재미있어요!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이징 결과: [['자연어', '처리', '는', '재미있는', '분야', '입니다', '.'], ['딥', '러닝', '은', '많은', '데이터', '를', '필요', '로', '합니다', '.'], ['한국어', 'NLP', '는', '정말', '재미있어요', '!']]\n"
     ]
    }
   ],
   "source": [
    "# 2. 토크나이징 (Tokenizing)\n",
    "okt = Okt()\n",
    "tokenized_sentences = [okt.morphs(sentence) for sentence in sentences]\n",
    "print(\"토크나이징 결과:\", tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 결과: [[3, 4, 1, 5, 6, 7, 2], [8, 9, 10, 11, 12, 13, 14, 15, 16, 2], [17, 18, 1, 19, 20, 21]]\n"
     ]
    }
   ],
   "source": [
    "# 3. 인코딩 (Encoding): 단어를 숫자로 변환\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_sentences)\n",
    "encoded_sentences = tokenizer.texts_to_sequences(tokenized_sentences)\n",
    "print(\"인코딩 결과:\", encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 결과: [[ 3  4  1  5  6  7  2  0  0  0]\n",
      " [ 8  9 10 11 12 13 14 15 16  2]\n",
      " [17 18  1 19 20 21  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 4. 패딩 (Padding): 길이를 맞추기 위해 0으로 채우기\n",
    "max_len = 10  # 최대 길이 설정\n",
    "padded_sentences = pad_sequences(encoded_sentences, maxlen=max_len, padding='post')\n",
    "print(\"패딩 결과:\", padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 임베딩 (Embedding)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # 단어 사전 크기\n",
    "embedding_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AIProject\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 간단한 임베딩 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "임베딩 결과 (첫번째 문장) :\n",
      " [[-0.04657022 -0.00470446 -0.027534   -0.0324476   0.00279471 -0.03550979\n",
      "  -0.01383502 -0.01590027]\n",
      " [ 0.00854915  0.003811   -0.01193186  0.00643337 -0.00663286 -0.01185126\n",
      "  -0.02511786  0.03809104]\n",
      " [ 0.04841013  0.02782908  0.03915615 -0.00219508 -0.02255455  0.00300518\n",
      "  -0.009718    0.02359561]\n",
      " [ 0.01629914 -0.04006492  0.02153833 -0.00278095 -0.02744147 -0.02630468\n",
      "  -0.02063364 -0.04050698]\n",
      " [-0.04756308 -0.0406273  -0.01435605 -0.04722878 -0.00356973 -0.04770284\n",
      "  -0.00090505 -0.01471011]\n",
      " [ 0.04236615 -0.01357054 -0.00191178  0.03510107  0.0468187   0.04746902\n",
      "   0.03452532  0.01020692]\n",
      " [-0.01717721  0.04814411  0.03692695 -0.01098335 -0.00513018 -0.04054489\n",
      "  -0.01790508 -0.02122538]\n",
      " [ 0.00793121 -0.02610731 -0.00844646 -0.02409626 -0.03796908 -0.00073588\n",
      "  -0.01892446 -0.04486957]\n",
      " [ 0.00793121 -0.02610731 -0.00844646 -0.02409626 -0.03796908 -0.00073588\n",
      "  -0.01892446 -0.04486957]\n",
      " [ 0.00793121 -0.02610731 -0.00844646 -0.02409626 -0.03796908 -0.00073588\n",
      "  -0.01892446 -0.04486957]]\n"
     ]
    }
   ],
   "source": [
    "# 패딩된 문장을 임베딩 층에 통과\n",
    "embeddings = model.predict(padded_sentences)\n",
    "print(\"임베딩 결과 (첫번째 문장) :\\n\", embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
