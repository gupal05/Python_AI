{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "from gtts import gTTS\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅 기록을 포함하여 응답을 생성하는 함수\n",
    "def chat(message, history):\n",
    "    # ChatOllama 모델 초기화\n",
    "    model = ChatOllama(model=\"gemma2\", temperature=0.7, verbose=False)\n",
    "    # 이전 대화 기록을 ChatOllama 형식으로 변환\n",
    "    chat_history = []\n",
    "    for human, ai in history:\n",
    "        chat_history.append(HumanMessage(content=human))\n",
    "        chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "    # 현재 메세지 추가\n",
    "    chat_history.append(HumanMessage(content=message))\n",
    "    \n",
    "    # 모델을 사용하여 응답 생성\n",
    "    response = model.invoke(chat_history)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, lang = 'ko'):\n",
    "    #임심 파일 생성\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n",
    "        temp_filename = fp.name\n",
    "    \n",
    "    # TTS 변환\n",
    "    #gtts를 활용\n",
    "    tts = gTTS(text = text, lang = lang)\n",
    "    tts.save(temp_filename)\n",
    "    return temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tts(text, lang):\n",
    "    if not text:\n",
    "        return None, \"텍스트를 입력해주세요.\"\n",
    "    try:\n",
    "        audio_file = text_to_speech(text, lang)\n",
    "        return audio_file, \"변환이 완료되었습니다. 아래에서 재생 또는 다운로드할 수 있습니다.\"\n",
    "    except Exception as e:\n",
    "        return None, f\"오류가 발생했습니다: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드클라우드 생성 함수\n",
    "def generate_wordcloud():\n",
    "    # 파일에서 텍스트 읽기\n",
    "    with open('./dataset/history.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # 워드클라우드 생성\n",
    "    wordcloud = WordCloud(\n",
    "        font_path='malgun',  # 한글 폰트 설정 (맑은 고딕)\n",
    "        background_color='white',\n",
    "        width=800,\n",
    "        height=600,\n",
    "        max_words=200,\n",
    "        max_font_size=100,\n",
    "        min_font_size=10,\n",
    "        random_state=42\n",
    "    ).generate(text)\n",
    "\n",
    "    # 워드클라우드 이미지를 파일로 저장\n",
    "    wordcloud_path = \"wordcloud_output.png\"\n",
    "    wordcloud.to_file(wordcloud_path)\n",
    "\n",
    "    # Gradio가 파일 경로를 출력할 수 있도록 반환\n",
    "    return wordcloud_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AIProject\\.venv\\lib\\site-packages\\gradio\\components\\chatbot.py:248: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gradio Tabbed Interface\n",
    "with gr.Blocks() as iface:\n",
    "    # Tab for Visualization (Word Cloud)\n",
    "    with gr.Tab(\"Text To Speech\"):\n",
    "        gr.Interface(\n",
    "            fn = process_tts,\n",
    "            inputs=[\n",
    "                gr.Textbox(lines=5, label=\"텍스트 입력\"),\n",
    "                gr.Dropdown(choices=['ko', 'en', 'ja', 'zh-cn'], label=\"언어 선택\", value='ko')\n",
    "            ],\n",
    "            outputs=[\n",
    "                gr.Audio(label=\"생성된 오디오\"),\n",
    "                gr.Textbox(label=\"상태 메세지\")\n",
    "            ],\n",
    "            title = \"Text to Speach Converter\",\n",
    "            description=\"텍스트를 입력하면 MP3 파일로 변환합니다.\"\n",
    "        )\n",
    "    \n",
    "    with gr.Tab(\"AI 챗봇\"):\n",
    "        gr.ChatInterface(\n",
    "            fn=chat,\n",
    "            examples=[\n",
    "                \"안녕하세요!\",\n",
    "                \"인공지능에 대해 설명해주세요.\",\n",
    "                \"파이썬의 장점은 무엇인가요?\"\n",
    "            ],\n",
    "            title = \"AI 챗봇\",\n",
    "            description=\"질문을 입력하면 AI가 답변합니다.\"\n",
    "        )\n",
    "    # Tab for Word Cloud\n",
    "    with gr.Tab(\"워드클라우드\"):\n",
    "        gr.Interface(\n",
    "            fn=generate_wordcloud,\n",
    "            inputs=None,  # 사용자 입력 없음\n",
    "            outputs=gr.Image(label=\"워드클라우드\"),  # 워드클라우드 이미지를 출력\n",
    "            title=\"워드클라우드 생성기\",\n",
    "            description=\"history.txt 파일의 내용을 기반으로 워드클라우드를 생성합니다.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 서버 실행\n",
    "iface.launch(server_port=7861, server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
